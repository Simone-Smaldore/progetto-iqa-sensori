{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94a7e2c6-c6e3-4d46-840b-dd7b87df1b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fa54c0-4c53-4458-ac8c-dd63b6b8317d",
   "metadata": {},
   "source": [
    "### Caricamento delle immagini in input in formato array numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9d02f45-0edd-4297-a262-8994a930fa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE_PATH_FOLDER = './Dati Sensori/Dataset Sensori Lavorato/1_M/1_M_1'\n",
    "IMAGE_PATH_FOLDER = './Dati Sensori/Dataset Distorto'\n",
    "#DISTORSIONI = ['Speckle-m0-s', 'Speckle-m1-s', 'Speckle-m2-s', 'Artefatti Riflessione-']\n",
    "DISTORSIONI = ['Speckle-m0-s', 'Speckle-m1-s', 'Speckle-m2-s']\n",
    "GRADI_DISTORSIONE = 5\n",
    "\n",
    "HEIGHT = 512\n",
    "WIDTH = 512\n",
    "\n",
    "TARGET_SIZE = (WIDTH, HEIGHT)\n",
    "CHANNELS = 1 # Scala di grigi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a8ea90d-12d4-44f8-81cf-509c8c8997ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sotto_cartelle(path):\n",
    "    return [x[1] for x in os.walk(path)][0]\n",
    "\n",
    "def get_immagini_cartella(path_cartella):\n",
    "    immagini_cartella = []\n",
    "    cartelle_soggetti = get_sotto_cartelle(path_cartella)\n",
    "    for soggetto in tqdm(cartelle_soggetti):\n",
    "        path_soggetto = f'{path_cartella}/{soggetto}'\n",
    "        cartelle_acquisizioni = get_sotto_cartelle(path_soggetto)\n",
    "        for acquisizione in cartelle_acquisizioni:\n",
    "            path_acquisizione = f'{path_soggetto}/{acquisizione}'\n",
    "            for filename in os.listdir(path_acquisizione):\n",
    "                # if (filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "                if (filename.endswith(\"_1.jpg\")):    \n",
    "                    path_file = f'{path_acquisizione}/{filename}'\n",
    "                    immagine = get_immagine_da_path(path_file)\n",
    "                    immagini_cartella.append(immagine)\n",
    "    return immagini_cartella\n",
    "                    \n",
    "def get_immagine_da_path(path_file):\n",
    "    image = Image.open(path_file).convert('L')\n",
    "    resized_image = image.resize(TARGET_SIZE)\n",
    "    image_array = np.array(resized_image)\n",
    "    normalized_image_array = image_array / 255.0\n",
    "    return normalized_image_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "051017d7-98e9-4513-a85e-e03d8b78a736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 14.43it/s]\n",
      "100%|██████████| 14/14 [00:01<00:00, 11.08it/s]\n",
      "100%|██████████| 14/14 [00:01<00:00, 10.64it/s]\n",
      "100%|██████████| 14/14 [00:01<00:00, 10.70it/s]\n",
      "100%|██████████| 14/14 [00:01<00:00, 10.66it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 15.01it/s]\n",
      "100%|██████████| 14/14 [00:01<00:00, 11.79it/s]\n",
      "100%|██████████| 14/14 [00:01<00:00, 12.34it/s]\n",
      "100%|██████████| 14/14 [00:01<00:00,  8.94it/s]\n",
      "100%|██████████| 14/14 [00:01<00:00, 12.02it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 15.19it/s]\n",
      "100%|██████████| 14/14 [00:01<00:00, 11.45it/s]\n",
      "100%|██████████| 14/14 [00:01<00:00, 10.76it/s]\n",
      "100%|██████████| 14/14 [00:01<00:00, 10.88it/s]\n",
      "100%|██████████| 14/14 [00:01<00:00, 10.73it/s]\n"
     ]
    }
   ],
   "source": [
    "image_list = []\n",
    "label_list = []\n",
    "\n",
    "for distorsione in DISTORSIONI:\n",
    "    path_distorsione = f'{IMAGE_PATH_FOLDER}/Dataset Sensori {distorsione}'\n",
    "    for grado_distorsione in range(GRADI_DISTORSIONE):\n",
    "        label = 100 - float(20 * (grado_distorsione))\n",
    "        path_cartella_grado = f'{path_distorsione}{grado_distorsione}'\n",
    "        immagini_grado = get_immagini_cartella(path_cartella_grado)\n",
    "        image_list.extend(immagini_grado)\n",
    "        label_to_append = [label for x in range(len(immagini_grado))] \n",
    "        label_list.extend(label_to_append)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # for root, dirs, files in os.walk(path_cartella_grado):\n",
    "        #     for file in files:\n",
    "        #         if(file\n",
    "        #        # print(root)\n",
    "        #        # for _dir in dirs:\n",
    "        #        #     print(_dir)\n",
    "        #        for _file in files:\n",
    "        #            print(_file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da019711-7c98-4447-8ffe-fee4224941d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.array(image_list)\n",
    "train_weights = np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ccfb58e-1668-443b-b646-756ab35ceaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(HEIGHT, WIDTH, CHANNELS)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)  # Un singolo output per il valore predetto\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "923e71a8-396a-4892-b0f4-c3d46106f99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mae', metrics = ['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1551ac73-dc4d-4f1f-98ef-849be8b51acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3075/3075 [==============================] - 345s 112ms/step - loss: 3.4013 - mae: 3.4013\n",
      "Epoch 2/30\n",
      "3075/3075 [==============================] - 341s 111ms/step - loss: 3.2428 - mae: 3.2428\n",
      "Epoch 3/30\n",
      "3075/3075 [==============================] - 341s 111ms/step - loss: 3.1054 - mae: 3.1054\n",
      "Epoch 4/30\n",
      "3075/3075 [==============================] - 342s 111ms/step - loss: 3.1230 - mae: 3.1230\n",
      "Epoch 5/30\n",
      "3075/3075 [==============================] - 342s 111ms/step - loss: 3.1261 - mae: 3.1261\n",
      "Epoch 6/30\n",
      "3075/3075 [==============================] - 342s 111ms/step - loss: 2.9905 - mae: 2.9905\n",
      "Epoch 7/30\n",
      "3075/3075 [==============================] - 342s 111ms/step - loss: 3.0050 - mae: 3.0050\n",
      "Epoch 8/30\n",
      "3075/3075 [==============================] - 342s 111ms/step - loss: 2.8768 - mae: 2.8768\n",
      "Epoch 9/30\n",
      "3075/3075 [==============================] - 342s 111ms/step - loss: 2.8665 - mae: 2.8665\n",
      "Epoch 10/30\n",
      "3075/3075 [==============================] - 342s 111ms/step - loss: 2.9854 - mae: 2.9854\n",
      "Epoch 11/30\n",
      "3075/3075 [==============================] - 342s 111ms/step - loss: 2.9267 - mae: 2.9267\n",
      "Epoch 12/30\n",
      "3075/3075 [==============================] - 342s 111ms/step - loss: 2.8325 - mae: 2.8325\n",
      "Epoch 13/30\n",
      "3075/3075 [==============================] - 342s 111ms/step - loss: 2.8494 - mae: 2.8494\n",
      "Epoch 14/30\n",
      "3075/3075 [==============================] - 345s 112ms/step - loss: 2.7237 - mae: 2.7237\n",
      "Epoch 15/30\n",
      "3075/3075 [==============================] - 345s 112ms/step - loss: 2.7108 - mae: 2.7108\n",
      "Epoch 16/30\n",
      "3075/3075 [==============================] - 345s 112ms/step - loss: 2.6628 - mae: 2.6628\n",
      "Epoch 17/30\n",
      "3075/3075 [==============================] - 346s 113ms/step - loss: 2.6589 - mae: 2.6589\n",
      "Epoch 18/30\n",
      "3075/3075 [==============================] - 346s 113ms/step - loss: 2.6240 - mae: 2.6240\n",
      "Epoch 19/30\n",
      "3075/3075 [==============================] - 344s 112ms/step - loss: 2.6281 - mae: 2.6281\n",
      "Epoch 20/30\n",
      "3075/3075 [==============================] - 345s 112ms/step - loss: 2.6557 - mae: 2.6557\n",
      "Epoch 21/30\n",
      "3075/3075 [==============================] - 375s 122ms/step - loss: 2.4989 - mae: 2.4989\n",
      "Epoch 22/30\n",
      "3075/3075 [==============================] - 7039s 2s/step - loss: 2.5713 - mae: 2.5713\n",
      "Epoch 23/30\n",
      "3075/3075 [==============================] - 3111s 1s/step - loss: 2.5565 - mae: 2.5565\n",
      "Epoch 24/30\n",
      "3075/3075 [==============================] - 344s 112ms/step - loss: 2.3757 - mae: 2.3757\n",
      "Epoch 25/30\n",
      "3075/3075 [==============================] - 343s 112ms/step - loss: 2.4645 - mae: 2.4645\n",
      "Epoch 26/30\n",
      "3075/3075 [==============================] - 344s 112ms/step - loss: 2.3601 - mae: 2.3601\n",
      "Epoch 27/30\n",
      "3075/3075 [==============================] - 344s 112ms/step - loss: 2.4344 - mae: 2.4344\n",
      "Epoch 28/30\n",
      "3075/3075 [==============================] - 344s 112ms/step - loss: 2.3397 - mae: 2.3397\n",
      "Epoch 29/30\n",
      "3075/3075 [==============================] - 344s 112ms/step - loss: 2.3415 - mae: 2.3415\n",
      "Epoch 30/30\n",
      "3075/3075 [==============================] - 344s 112ms/step - loss: 2.2383 - mae: 2.2383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3efc69070>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_images, y=train_weights, batch_size=1, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3e9071f6-20f3-4c14-820e-779c0e2c0e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-09 15:28:07.925549: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 23s 218ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fa461278-e8fa-43cb-85ef-b452d3d14e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[97.90513 ],\n",
       "       [95.98184 ],\n",
       "       [96.95886 ],\n",
       "       ...,\n",
       "       [24.281197],\n",
       "       [22.211346],\n",
       "       [22.889868]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf774b8-6919-4531-acd3-1a9e92e15cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Modelli/modello_pesi_inizializzati_v2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Modelli/modello_pesi_inizializzati_v2/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./Modelli/modello_pesi_inizializzati_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "88aa9565-09d9-4e82-91e4-bdc1095f5e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.407417297363281"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([i[0] for i in predictions]  - train_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb314e9-0ca1-4176-919a-0203f849e370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
